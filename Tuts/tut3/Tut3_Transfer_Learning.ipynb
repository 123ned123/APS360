{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e9a85b",
   "metadata": {},
   "source": [
    "## Prac preavious session in building a model and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f775ba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(20)\n",
    "\n",
    "class PracANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PracANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(256*256*3, 1084)\n",
    "        self.fc2 = nn.Linear(1084, 512)\n",
    "        self.fc3 = nn.Linear(512, 257)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 256*256*3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_accuracy(model, train = False, data_loader=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(imgs).to(device)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def get_accuracy_no_model(prediction,labels):\n",
    "    _, predicted = torch.max(prediction.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def train(model, train_loader, valid_loader, lr=0.01, num_epochs = 1):\n",
    "    print(\"Starting training...\")\n",
    "    criterian = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    iteration_count = 0\n",
    "    print(\"Beginning epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            print(\"in the loop\")\n",
    "            model.train()\n",
    "            print(\"model in train mode\")\n",
    "            out = model(imgs).to(device)\n",
    "            loss = criterian(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print(\"after optimization step\")\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(iteration_count)\n",
    "            losses.append(loss.item())\n",
    "            train_acc.append(get_accuracy_no_model(out, labels))\n",
    "            # val_acc.append(get_accuracy_no_model(model, train=False, data_loader=valid_loader))\n",
    "            iteration_count += 1\n",
    "            print(\"Iteration: \", iteration_count, \" Loss: \", loss.item(), \" Train Accuracy: \", train_acc[-1])\n",
    "        print(\"Epoch: \", epoch+1, \" Loss: \", loss.item(), \" Train Accuracy: \", train_acc[-1])\n",
    "\n",
    "    # plotting \n",
    "    plt.title(\"Training Curve\")        \n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Accuracy: \", train_acc[-1])\n",
    "    print(\"Final Validation Accuracy: \", val_acc[-1])\n",
    "    \n",
    "    return iters, losses, train_acc, val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3511855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images:  30607\n"
     ]
    }
   ],
   "source": [
    "# Dataset preparation \n",
    "\n",
    "from torchvision import datasets, transforms \n",
    "from skimage import color\n",
    "import numpy as np\n",
    "\n",
    "def ensure_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "my_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Lambda(ensure_rgb),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Caltech_data = datasets.Caltech256('data', download=True,\n",
    "#                              transform=my_transform)\n",
    "Caltech_data = datasets.ImageFolder('data/Caltech256', transform=my_transform)\n",
    "print(\"Total number of images: \", len(Caltech_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "992b733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation set\n",
    "\n",
    "train_size = int(0.8 * len(Caltech_data))\n",
    "valid_size = len(Caltech_data) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(Caltech_data, [train_size, valid_size])\n",
    "\n",
    "# create dataloaders \n",
    "\n",
    "pin_memory = True if device.type == 'cuda' else False\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=pin_memory)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "457b442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Image batch shape: torch.Size([32, 3, 256, 256])\n",
      "Label batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx}\")\n",
    "    print(\"Image batch shape:\", imgs.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    break  # remove break to go through all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e9647d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Beginning epochs...\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  1  Loss:  5.572234153747559  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  2  Loss:  5.498388290405273  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  3  Loss:  5.481864929199219  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  4  Loss:  5.581925392150879  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  5  Loss:  5.536680221557617  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  6  Loss:  5.968446731567383  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  7  Loss:  5.798617362976074  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  8  Loss:  6.398227214813232  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  9  Loss:  5.881986618041992  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  10  Loss:  5.801335334777832  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  11  Loss:  5.668697834014893  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  12  Loss:  5.6079864501953125  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  13  Loss:  5.905929088592529  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  14  Loss:  5.4103899002075195  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  15  Loss:  5.35881233215332  Train Accuracy:  0.09375\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  16  Loss:  5.832802772521973  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  17  Loss:  5.746723175048828  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  18  Loss:  5.555411338806152  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  19  Loss:  5.364790439605713  Train Accuracy:  0.125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  20  Loss:  5.642108917236328  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  21  Loss:  5.713492393493652  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  22  Loss:  5.450071334838867  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  23  Loss:  5.483654022216797  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  24  Loss:  5.504838943481445  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  25  Loss:  5.571395397186279  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  26  Loss:  5.4632344245910645  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  27  Loss:  5.358748435974121  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  28  Loss:  5.456080436706543  Train Accuracy:  0.09375\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  29  Loss:  5.463831424713135  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  30  Loss:  5.467191696166992  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  31  Loss:  5.5216779708862305  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  32  Loss:  5.489494800567627  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  33  Loss:  5.422064781188965  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  34  Loss:  5.5988874435424805  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  35  Loss:  5.518496036529541  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  36  Loss:  5.64487886428833  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  37  Loss:  5.472640514373779  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  38  Loss:  5.489326477050781  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  39  Loss:  5.381982326507568  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  40  Loss:  5.476298809051514  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  41  Loss:  5.453670501708984  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  42  Loss:  5.490428447723389  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  43  Loss:  5.489601135253906  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  44  Loss:  5.5404133796691895  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  45  Loss:  5.441648006439209  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  46  Loss:  5.479220390319824  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  47  Loss:  5.440924644470215  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  48  Loss:  5.532719612121582  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  49  Loss:  5.457151412963867  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  50  Loss:  5.514738082885742  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  51  Loss:  5.572808265686035  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  52  Loss:  5.5674004554748535  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  53  Loss:  5.480414390563965  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  54  Loss:  5.526795864105225  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  55  Loss:  5.486453533172607  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  56  Loss:  5.286783218383789  Train Accuracy:  0.09375\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  57  Loss:  5.433833122253418  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  58  Loss:  5.6747283935546875  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  59  Loss:  5.371039390563965  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  60  Loss:  5.109259128570557  Train Accuracy:  0.09375\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  61  Loss:  5.637181282043457  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  62  Loss:  5.571665287017822  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  63  Loss:  5.427613258361816  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  64  Loss:  5.376909255981445  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  65  Loss:  5.376953125  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  66  Loss:  5.482045650482178  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  67  Loss:  5.3701348304748535  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  68  Loss:  5.621736526489258  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  69  Loss:  5.31809139251709  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  70  Loss:  5.430394172668457  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  71  Loss:  5.5312395095825195  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  72  Loss:  5.415628433227539  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  73  Loss:  5.48538875579834  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  74  Loss:  5.243393421173096  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  75  Loss:  5.422004699707031  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  76  Loss:  5.491854667663574  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  77  Loss:  5.503710746765137  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  78  Loss:  5.419020652770996  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  79  Loss:  5.508203506469727  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  80  Loss:  5.500299453735352  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  81  Loss:  5.319784164428711  Train Accuracy:  0.09375\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  82  Loss:  5.381636619567871  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  83  Loss:  5.383878707885742  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  84  Loss:  5.525397777557373  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  85  Loss:  5.578941345214844  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  86  Loss:  5.256186485290527  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  87  Loss:  5.446245193481445  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  88  Loss:  5.244785785675049  Train Accuracy:  0.15625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  89  Loss:  5.345092296600342  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  90  Loss:  5.459883213043213  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  91  Loss:  5.512448787689209  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  92  Loss:  5.348601341247559  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  93  Loss:  5.557818412780762  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  94  Loss:  5.448899269104004  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  95  Loss:  5.431410789489746  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  96  Loss:  5.452693939208984  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  97  Loss:  5.5578932762146  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  98  Loss:  5.238979339599609  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  99  Loss:  5.492208003997803  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  100  Loss:  5.399004936218262  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  101  Loss:  5.140783309936523  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  102  Loss:  5.467585563659668  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  103  Loss:  5.460232734680176  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  104  Loss:  5.33486270904541  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  105  Loss:  5.646022319793701  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  106  Loss:  5.503059387207031  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  107  Loss:  5.236727714538574  Train Accuracy:  0.125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  108  Loss:  5.342113018035889  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  109  Loss:  5.438610076904297  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  110  Loss:  5.2805376052856445  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  111  Loss:  5.36469030380249  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  112  Loss:  5.3694047927856445  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  113  Loss:  5.476408004760742  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  114  Loss:  5.50834846496582  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  115  Loss:  5.500555992126465  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  116  Loss:  5.446418285369873  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  117  Loss:  5.3173394203186035  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  118  Loss:  5.4445390701293945  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  119  Loss:  5.31019401550293  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  120  Loss:  5.019355773925781  Train Accuracy:  0.1875\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  121  Loss:  5.180258750915527  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  122  Loss:  5.89845609664917  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  123  Loss:  5.3850297927856445  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  124  Loss:  5.46691370010376  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  125  Loss:  5.474717140197754  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  126  Loss:  5.2545928955078125  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  127  Loss:  5.570372581481934  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  128  Loss:  5.517199516296387  Train Accuracy:  0.0\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  129  Loss:  5.104359149932861  Train Accuracy:  0.125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  130  Loss:  5.5673370361328125  Train Accuracy:  0.03125\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  131  Loss:  5.437740325927734  Train Accuracy:  0.0625\n",
      "in the loop\n",
      "model in train mode\n",
      "after optimization step\n",
      "Iteration:  132  Loss:  5.428712368011475  Train Accuracy:  0.0625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## sanity check the data\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m## move model and tensors to device for training\u001b[39;00m\n\u001b[32m      3\u001b[39m model = PracANN().to(device)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, valid_loader, lr, num_epochs)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBeginning epochs...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[39m, in \u001b[36mDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    index (int): Index\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m \u001b[33;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m path, target = \u001b[38;5;28mself\u001b[39m.samples[index]\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m     sample = \u001b[38;5;28mself\u001b[39m.transform(sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[39m, in \u001b[36mdefault_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\torchvision\\datasets\\folder.py:263\u001b[39m, in \u001b[36mpil_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpil_loader\u001b[39m(path: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Image.Image:\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m         img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m img.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Project\\Python_Env\\AI\\Lib\\site-packages\\PIL\\Image.py:3504\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3501\u001b[39m     fp = io.BytesIO(fp.read())\n\u001b[32m   3502\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3504\u001b[39m prefix = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3506\u001b[39m preinit()\n\u001b[32m   3508\u001b[39m warning_messages: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "## sanity check the data\n",
    "## move model and tensors to device for training\n",
    "model = PracANN().to(device)\n",
    "\n",
    "train(model, train_loader, valid_loader, num_epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in valid_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(\"Test Accuracy: \", correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9fea0",
   "metadata": {},
   "source": [
    "## Copilot Code ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879c183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed458919",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9aba82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\miniforge3\\envs\\ml\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\miniforge3\\envs\\ml\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models\n",
    "\n",
    "alexNet = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2309d6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6eceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexNet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2322e6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imread() missing 1 required positional argument: 'fname'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# load colour image \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m img = \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: imread() missing 1 required positional argument: 'fname'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# load colour image \n",
    "\n",
    "img = plt.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a279f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexNetConv = alexNet.features[0]\n",
    "y = alexNetConv(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
